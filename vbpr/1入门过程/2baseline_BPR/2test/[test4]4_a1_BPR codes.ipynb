{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[test4]4_a1_BPR codes.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python2","display_name":"Python 2"}},"cells":[{"metadata":{"id":"GRIL1C0dfv1q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"0dbde87a-0bd3-4d41-9070-94974f0322bf","executionInfo":{"status":"ok","timestamp":1552538374176,"user_tz":-480,"elapsed":22236,"user":{"displayName":"Jacob Ji","photoUrl":"https://lh3.googleusercontent.com/-zoRekIA1fCY/AAAAAAAAAAI/AAAAAAAACBQ/eV12vlBRQiA/s64/photo.jpg","userId":"06638368627777389358"}}},"cell_type":"code","source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# 授权登录，仅第一次的时候会鉴权\n","def login_google_drive():\n","  auth.authenticate_user()\n","  gauth = GoogleAuth()\n","  gauth.credentials = GoogleCredentials.get_application_default()\n","  drive = GoogleDrive(gauth)\n","  return drive\n","\n","# 列出id对应目录的所有文件\n","# \"q\" 查询条件教程详见：https://developers.google.com/drive/v2/web/search-parameters\n","def list_file(drive, dir_id_str):\n","  file_list = drive.ListFile({'q': dir_id_str+\" in parents and trashed=false\"}).GetList()\n","  for file1 in file_list:\n","    print('title: %s, id: %s, mimeType: %s' % (file1['title'], file1['id'], file1[\"mimeType\"]))\n","\n","def cache_data(file_id_str):\n","  # id 替换成上一步读取到的对应文件 id\n","  u_data = drive.CreateFile({'id': file_id_str}) \n","  \n","  #这里的下载操作只是缓存，不会在你的Google Drive 目录下多下载一个文件\n","  u_data.GetContentFile('u.data', \"text/csv\")\n","  print(\"缓存成功\")\n","\n","def load_data():\n","    titles = []\n","    print(\"正在加载数据...\")\n","    with open(\"u.data\", \"r\") as f:\n","        for line in f.readlines():\n","            titles.append(line.strip())\n","            \n","    print(\"一共加载了 %s 个标题\" % len(titles))\n","\n","    return titles\n","  \n","drive = login_google_drive()\n","#list_file(drive,\"'1DCdKTVKMGR_ei-NWE-68Y_mRFPf5RQhv'\")\n","cache_data(\"14Eha5chGz6RNWIYALvZBGI8Q-yAUmj7l\")\n","titles = load_data()\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["缓存成功\n","正在加载数据...\n","一共加载了 100000 个标题\n"],"name":"stdout"}]},{"metadata":{"id":"RwspxwpUf8DH","colab_type":"text"},"cell_type":"markdown","source":["## 备注：修改参数：BatchSize:1028, LR:0.02, RR:0.001, k:10"]},{"metadata":{"id":"F6XKwWUWgCFZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1702},"outputId":"7f9ac5fe-f974-405b-af30-f4a0d8329a89","executionInfo":{"status":"ok","timestamp":1552545017616,"user_tz":-480,"elapsed":1154149,"user":{"displayName":"Jacob Ji","photoUrl":"https://lh3.googleusercontent.com/-zoRekIA1fCY/AAAAAAAAAAI/AAAAAAAACBQ/eV12vlBRQiA/s64/photo.jpg","userId":"06638368627777389358"}}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import os\n","import random\n","from collections import defaultdict\n","\n","\n","def load_data():\n","    user_ratings = defaultdict(set)\n","    max_u_id = -1\n","    max_i_id = -1\n","    with open('u.data','r') as f:\n","        for line in f.readlines():\n","            u,i,_,_ = line.split(\"\\t\")\n","            u = int(u)\n","            i = int(i)\n","            user_ratings[u].add(i)\n","            max_u_id = max(u,max_u_id)\n","            max_i_id = max(i,max_i_id)\n","\n","\n","    print(\"max_u_id:\",max_u_id)\n","    print(\"max_i_idL\",max_i_id)\n","\n","    return max_u_id,max_i_id,user_ratings\n","\n","def generate_test(user_ratings):\n","    \"\"\"\n","    对每一个用户u，在user_ratings中随机找到他评分过的一部电影i,保存在user_ratings_test，\n","    后面构造训练集和测试集需要用到。\n","    \"\"\"\n","    user_test = dict()\n","    for u,i_list in user_ratings.items():\n","        user_test[u] = random.sample(user_ratings[u],1)[0]\n","    return user_test\n","\n","\n","def generate_train_batch(user_ratings,user_ratings_test,item_count,batch_size=1028):\n","    \"\"\"\n","    构造训练用的三元组\n","    对于随机抽出的用户u，i可以从user_ratings随机抽出，而j也是从总的电影集中随机抽出，当然j必须保证(u,j)不在user_ratings中\n","    \"\"\"\n","    t = []\n","    for b in range(batch_size):\n","        u = random.sample(user_ratings.keys(),1)[0]\n","        i = random.sample(user_ratings[u],1)[0]\n","        while i==user_ratings_test[u]:\n","            i = random.sample(user_ratings[u],1)[0]\n","\n","        j = random.randint(1,item_count)\n","        while j in user_ratings[u]:\n","            j = random.randint(1,item_count)\n","\n","        t.append([u,i,j])\n","\n","    return np.asarray(t)\n","\n","\n","def generate_test_batch(user_ratings,user_ratings_test,item_count):\n","    \"\"\"\n","    对于每个用户u，它的评分电影i是我们在user_ratings_test中随机抽取的，它的j是用户u所有没有评分过的电影集合，\n","    比如用户u有1000部电影没有评分，那么这里该用户的测试集样本就有1000个\n","    \"\"\"\n","    for u in user_ratings.keys():\n","        t = []\n","        i = user_ratings_test[u]\n","        for j in range(1,item_count + 1):\n","            if not(j in user_ratings[u]):\n","                t.append([u,i,j])\n","        yield np.asarray(t)\n","        \n","        \n","  \n","\n","def bpr_mf(user_count,item_count,hidden_dim):\n","    u = tf.placeholder(tf.int32,[None])\n","    i = tf.placeholder(tf.int32,[None])\n","    j = tf.placeholder(tf.int32,[None])\n","\n","    user_emb_w = tf.get_variable(\"user_emb_w2\", [user_count + 1, hidden_dim],\n","                                 initializer=tf.random_normal_initializer(0, 0.1))\n","    item_emb_w = tf.get_variable(\"item_emb_w2\", [item_count + 1, hidden_dim],\n","                                 initializer=tf.random_normal_initializer(0, 0.1))\n","\n","    u_emb = tf.nn.embedding_lookup(user_emb_w, u)\n","    i_emb = tf.nn.embedding_lookup(item_emb_w, i)\n","    j_emb = tf.nn.embedding_lookup(item_emb_w, j)\n","\n","\n","    x = tf.reduce_sum(tf.multiply(u_emb,(i_emb-j_emb)),1,keepdims=True)\n","\n","    mf_auc = tf.reduce_mean(tf.to_float(x>0))\n","\n","    l2_norm = tf.add_n([\n","        tf.reduce_sum(tf.multiply(u_emb, u_emb)),\n","        tf.reduce_sum(tf.multiply(i_emb, i_emb)),\n","        tf.reduce_sum(tf.multiply(j_emb, j_emb))\n","    ])\n","\n","    regulation_rate = 0.0001\n","    bprloss = regulation_rate * l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n","\n","    train_op = tf.train.GradientDescentOptimizer(0.02).minimize(bprloss)\n","    return u, i, j, mf_auc, bprloss, train_op\n","\n","\n","user_count,item_count,user_ratings = load_data()\n","user_ratings_test = generate_test(user_ratings)\n","\n","with tf.Session() as sess:\n","    u,i,j,mf_auc,bprloss,train_op = bpr_mf(user_count,item_count,20)\n","    sess.run(tf.global_variables_initializer())\n","\n","    for epoch in range(1,10):\n","        _batch_bprloss = 0\n","        for k in range(1,1000):\n","            uij = generate_train_batch(user_ratings,user_ratings_test,item_count)\n","            _bprloss,_train_op = sess.run([bprloss,train_op],\n","                                          feed_dict={u:uij[:,0],i:uij[:,1],j:uij[:,2]})\n","\n","            _batch_bprloss += _bprloss\n","\n","        print(\"epoch:\",epoch)\n","        print(\"bpr_loss:\",_batch_bprloss / k)\n","        print(\"_train_op\")\n","\n","        user_count = 0\n","        _auc_sum = 0.0\n","\n","        for t_uij in generate_test_batch(user_ratings, user_ratings_test, item_count):\n","            _auc, _test_bprloss = sess.run([mf_auc, bprloss],\n","                                              feed_dict={u: t_uij[:, 0], i: t_uij[:, 1], j: t_uij[:, 2]}\n","                                              )\n","            user_count += 1\n","            _auc_sum += _auc\n","        print(\"test_loss: \", _test_bprloss, \"test_auc: \", _auc_sum / user_count)\n","        print(\"\")\n","    variable_names = [v.name for v in tf.trainable_variables()]\n","    values = sess.run(variable_names)\n","    for k, v in zip(variable_names, values):\n","        print(\"Variable: \", k)\n","        print(\"Shape: \", v.shape)\n","        print(v)\n","\n","#  0号用户对这个用户对所有电影的预测评分\n","session1 = tf.Session()\n","u1_dim = tf.expand_dims(values[0][0], 0)\n","u1_all = tf.matmul(u1_dim, values[1],transpose_b=True)\n","result_1 = session1.run(u1_all)\n","print (result_1)\n","\n","print(\"以下是给用户0的推荐：\")\n","p = np.squeeze(result_1)\n","p[np.argsort(p)[:-5]] = 0\n","for index in range(len(p)):\n","    if p[index] != 0:\n","        print (index, p[index])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["('max_u_id:', 943)\n","('max_i_idL', 1682)\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From <ipython-input-3-300d846d0c96>:92: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","('epoch:', 1)\n","('bpr_loss:', 0.7544044412530817)\n","_train_op\n","('test_loss: ', 0.7609094, 'test_auc: ', 0.5091226293092711)\n","\n","('epoch:', 2)\n","('bpr_loss:', 0.7535336311157044)\n","_train_op\n","('test_loss: ', 0.7598756, 'test_auc: ', 0.5091289403268249)\n","\n","('epoch:', 3)\n","('bpr_loss:', 0.7526552761877859)\n","_train_op\n","('test_loss: ', 0.7588768, 'test_auc: ', 0.5091996647206812)\n","\n","('epoch:', 4)\n","('bpr_loss:', 0.7518116079412542)\n","_train_op\n","('test_loss: ', 0.7579481, 'test_auc: ', 0.509218959053603)\n","\n","('epoch:', 5)\n","('bpr_loss:', 0.7509534100631813)\n","_train_op\n","('test_loss: ', 0.7570056, 'test_auc: ', 0.5093115083367118)\n","\n","('epoch:', 6)\n","('bpr_loss:', 0.7501882346900733)\n","_train_op\n","('test_loss: ', 0.75610816, 'test_auc: ', 0.5093252083799216)\n","\n","('epoch:', 7)\n","('bpr_loss:', 0.7493821883106137)\n","_train_op\n","('test_loss: ', 0.75520796, 'test_auc: ', 0.5093670534932925)\n","\n","('epoch:', 8)\n","('bpr_loss:', 0.7485885762118243)\n","_train_op\n","('test_loss: ', 0.75433195, 'test_auc: ', 0.5094359064839379)\n","\n","('epoch:', 9)\n","('bpr_loss:', 0.7479231509121808)\n","_train_op\n","('test_loss: ', 0.75351477, 'test_auc: ', 0.5094606258886919)\n","\n","('Variable: ', u'user_emb_w2:0')\n","('Shape: ', (944, 20))\n","[[-0.02805687 -0.05113089 -0.20006195 ...  0.13504347 -0.07002072\n","  -0.03041079]\n"," [ 0.1134126   0.04954122  0.13224739 ...  0.05567856  0.1139714\n","  -0.02127774]\n"," [ 0.09369983 -0.05943354 -0.06311294 ...  0.1263762   0.13576283\n","   0.00554349]\n"," ...\n"," [ 0.14497237 -0.04538504  0.14259736 ... -0.02899066  0.12152919\n","  -0.04028466]\n"," [-0.01732294 -0.01082346 -0.01286365 ... -0.06327316 -0.01973233\n","  -0.00026434]\n"," [ 0.03480039 -0.03801275 -0.09013649 ... -0.2339012  -0.05586759\n","   0.19179843]]\n","('Variable: ', u'item_emb_w2:0')\n","('Shape: ', (1683, 20))\n","[[ 0.03241896  0.0649669   0.03659097 ... -0.05871683 -0.01217216\n","   0.09273309]\n"," [ 0.08780891  0.11293384  0.04981104 ...  0.02615051  0.01421032\n","   0.06435698]\n"," [-0.03973436 -0.09064128  0.11876646 ...  0.12494084 -0.01887599\n","  -0.14998369]\n"," ...\n"," [ 0.13869648 -0.04644543 -0.03842348 ... -0.09570584 -0.01688911\n","  -0.0322345 ]\n"," [ 0.0848757   0.148503   -0.22003587 ...  0.07220404  0.07513629\n","  -0.0212267 ]\n"," [ 0.05417607 -0.1074295  -0.0162138  ...  0.00366806 -0.2152392\n","   0.02508443]]\n","[[-0.01144666  0.02067733 -0.00941517 ...  0.03174351  0.066066\n","   0.03493899]]\n","以下是给用户0的推荐：\n","(135, 0.10693045)\n","(817, 0.10587473)\n","(942, 0.10979048)\n","(1012, 0.116516896)\n","(1093, 0.12211295)\n"],"name":"stdout"}]}]}