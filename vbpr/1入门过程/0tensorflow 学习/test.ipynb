{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据的预处理和加载\n",
    "def load_data():\n",
    "    user_ratings = defaultdict(set) #注意这里定义的数据格式，dict[set]\n",
    "    max_u_id = -1\n",
    "    max_i_id = -1\n",
    "    with open('data/u.data', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            u,i,_,_ = line.split(\"\\t\")  #这里切分数据\n",
    "            u = int(u)  #这里将用户编号变换成int格式\n",
    "            i = int(i)  \n",
    "            user_ratings[u].add(i)  #这里制作成set形式的[u,i]加入进user_ratings集合\n",
    "            max_u_id = max(u,max_u_id) #这里的max值即用户的数量，以下同理为商品数\n",
    "            max_i_id = max(i,max_i_id) \n",
    "    \n",
    "    print(\"max_u_id:\",max_u_id) #这里应该输出943\n",
    "    print(\"max_i_idL\",max_i_id) #这里应该输出1682\n",
    "    \n",
    "    return max_u_id,max_i_id, user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  这里对每个用户u，在user_ratings中随机找到一部他评分过的一部电影i,\n",
    "#  然后保存在user_ratings_test,后面构造训练集和测试集需要用到\n",
    "#  ?还不是太理解这里的test有什么用\n",
    "def generate_test(user_ratings):\n",
    "    user_test = dict()\n",
    "    for u,i_list in user_ratings.items(): #注意这里循环时，u对应user,i_list对应item集，都是一一对应的\n",
    "        user_test[u] = random.sample(user_ratings[u],1)[0]\n",
    "    return user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据是<u,i,j>的三元组\n",
    "# 对于随机抽出的用户u，i可以从user_ratings随机抽出，而j也是从总的电影集中随机抽出，\n",
    "# 当然j必须保证(u,j)不在user_ratings中,也就是用户u未作出反应的电影对象\n",
    "# 这里采用随机抽样的原因是，论文中提到采用 Bootstrap Sampling的方法\n",
    "def generate_train_batch(user_ratings, user_ratings_test, item_count, batch_size=512):\n",
    "    t = []  # 创建训练集\n",
    "    for b in range(batch_size): #注意这里规定每个训练集大小为512条[u,i,j]\n",
    "        u = random.sample(user_ratings.keys(),1)[0] \n",
    "        i = random.sample(user_ratings[u],1)[0]\n",
    "        while i == user_ratings_test[u]:\n",
    "            i = random.sample(user_ratings[u],1)[0]\n",
    "        \n",
    "        j = random.randint(1,item_count)\n",
    "        while j in user_ratings[u]:\n",
    "            j = random.randint(1,item_count)\n",
    "        \n",
    "        t.append([u,i,j])\n",
    "        \n",
    "    return np.asarray(t) #调用Numpy库的一个函数，将输入的t转换为浮点数值格式的array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于每个用户u,他的评分电影i是在user_ratings_test中随机抽取的，\n",
    "# 他的j是用户u所有没有评分过的电影集合\n",
    "# 比如用户u有1000部电影没有评分，那么这里该用户的测试集样本就有1000个\n",
    "def generate_test_batch(user_ratings, user_ratings_test, item_count):\n",
    "    for u in user_ratings.keys():\n",
    "        t = []\n",
    "        i = user_ratings_test[u]\n",
    "        for j in range(1, item_count+1):\n",
    "            if not(j in user_ratings[u]):\n",
    "                t.append([u,i,j])\n",
    "        yield np.asarray(t)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 论文中提到的参数Theta，其实是用户矩阵和物品矩阵对应的值\n",
    "    # 对于我们的模型来说，可以简单理解为由id 到embedding的转化\n",
    "def bpr_mf(user_count, item_count, hidden_dim):\n",
    "    \n",
    "    u = tf.placeholder(tf.int32, [None]) #?不知道这里的None指的是什么\n",
    "    i = tf.placeholder(tf.int32, [None])\n",
    "    j = tf.placeholder(tf.int32, {None})\n",
    "    \n",
    "    # 注意这里的hidden_dim就是我们矩阵分解的隐含维度k\n",
    "    # user_emb_w对应矩阵W, item_emb_w对应矩阵H\n",
    "    user_emb_w = tf.get_variable(\"user_emb_w\", [user_count+1, hidden_dim],\n",
    "                                initializer = tf.random_normal_initializer(0, 0.1)) \n",
    "    # 注意这里的初始化tensor生成的是服从正态分布(0,0.1)\n",
    "    item_emb_w = tf.get_variable(\"item_emb_w\", [item_count+1, hidden_dim],\n",
    "                                initializer = tf.random_normal_initializer(0, 0.1))\n",
    "    \n",
    "    u_emb = tf.nn.embedding_lookup(user_emb_w, u)  # 这里是想用特定u来从大矩阵中检索\n",
    "    i_emb = tf.nn.embedding_lookup(item_emb_w, i)  # 这里的i也同理\n",
    "    j_emb = tf.nn.embedding_lookup(item_emb_w, j)  # j同理\n",
    "    \n",
    "    # MF predict: u_i > u_j\n",
    "    # keep_dims=True:按照行的维度求和\n",
    "    x = tf.reduce_sum(tf.multiply(u_emb, (i_emb-j_emb)),1,keep_dims=True) # ?keep_dims不知道什么意思\n",
    "    # loss1 = - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n",
    "    \n",
    "    # AUC for one user:\n",
    "    # reasonable if all (u,i,j) pairs are from the same user\n",
    "    # \n",
    "    # average AUC = mean( auc for each user in test set)\n",
    "    mf_auc = tf.reduce_mean(tf.to_float(x>0))\n",
    "    \n",
    "    l2_norm = tf.add_n([\n",
    "        tf.reduce_sum(tf.multiply(u_emb, u_emb)), #？所以这里为什么要平方再求和\n",
    "        tf.reduce_sum(tf.multiply(i_emb, i_emb)),\n",
    "        tf.reduce_sum(tf.multiply(j_emb, j_emb))\n",
    "    ])\n",
    "    \n",
    "    regulation_rate = 0.0001\n",
    "    bprloss = regulation_rate * l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n",
    "    # ?然后这个损失函数也没看懂。。\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(bprloss)\n",
    "    \n",
    "    return u,i,j,mf_auc,bprloss,train_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2333代码实在看不懂，我还是继续滚回去看tensorflow吧。\n",
    "user_count,item_count,user_ratings = load_data()\n",
    "user_ratins_test = generate_test(user_ratings)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    u,i,j,mf_auc,bprloss,train_op = bpr_mf(user_count, item_count, 20)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(1,4): # 这里为了测试方便，也就迭代4次\n",
    "        _batch_bprloss = 0\n",
    "        for k in range(1,5000):\n",
    "            uij = generate_train_batch(user_ratings, user_ratings_test, item_count)\n",
    "            _bprloss, _train_op  = sees.run([bprloss,train_op],\n",
    "                                           feed_dict={u:uij[:,0],i:uij[:,j],j:uij[:,2]})\n",
    "            _batch_bprloss += _bprloss\n",
    "            \n",
    "            print(\"epoch:\", epoch)\n",
    "            print(\"bpr_loss:\", _batch_bprloss / k)\n",
    "            print(\"_train_op\")\n",
    "            \n",
    "            user_count = 0\n",
    "            _auc_sum = 0.0\n",
    "            \n",
    "            for t_uij in generate_train_batch(user_ratings, user_ratings_test, item_count):\n",
    "                _auc, _test_bprloss = sess.run([mf_auc, bprloss],\n",
    "                                              feed_dict={u:t_uij[:,0],i:t_uij[:,1],j:t_uij[:,2]})\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
