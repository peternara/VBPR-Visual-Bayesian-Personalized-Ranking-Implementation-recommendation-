{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced BPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓这里比较疑问的是，corpus到底做了怎么样的处理<br>\n",
    "√ 好了明白了，详见(mock_corpus.py文件)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from:  data/amzn/reviews_Women_ALL_scraped.csv\n",
      "generating stats...\n",
      "84090 302230 714381\n",
      "Loading image features from:  data/amzn/image_features_Women.b\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "extracted image feature count:  300401\n"
     ]
    }
   ],
   "source": [
    "from corpus import Corpus \n",
    "# corpus是管理数据集的工具库\n",
    "corpus = Corpus()\n",
    "#准备数据集\n",
    "reviews_path = \"data/amzn/reviews_Women_ALL_scraped.csv\" \n",
    "images_path = \"data/amzn/image_features_Women.b\" \n",
    "\n",
    "corpus.load_data(reviews_path, images_path, 5, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Testbench\n",
    "\n",
    "We need to start a tensorflow session and choose a BRP sampling method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里sampling就是将上述的数据进行再一次加工，成对，如<u,i,j>\n",
    "这里sample400次数，每次的batch大小为512，即用random任取不重复的u,i,j，要确保i是test_ratings或val_ratings中没有出现过的但在user_items中出现过的；而j则不能在user_items中出现过。\n",
    "<br>❓可是这里的val_ratings和test_ratings到底代表什么啊，为啥不能让i出现过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sampling\n",
    "\n",
    "sampler = sampling.Uniform()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR\n",
    "\n",
    "First let's test BPR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR - K=20, reg_lf: 10.00, reg_bias=0.01\n"
     ]
    }
   ],
   "source": [
    "#clear the graph if you rerun this cell\n",
    "tf.reset_default_graph()\n",
    "session = tf.Session()\n",
    "\n",
    "from models.bpr import BPR\n",
    "K=20\n",
    "reg=10.0\n",
    "bias_reg=0.01\n",
    "bpr = BPR(session, corpus, sampler, K, reg, bias_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iterations: 10, batch_size: 128, batch_count: 400\n",
      "1 27.5626740456 733.75\n",
      "2 27.186975956 646.483\n",
      "3 27.8556120396 562.475\n",
      "4 26.7566859722 489.321\n",
      "5 25.9751479626 427.084\n",
      "6 25.9668660164 370.275\n",
      "7 25.9990429878 323.807\n",
      "8 26.5436167717 283.306\n",
      "9 26.1647830009 247.311\n",
      "10 26.4177498817 216.746\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "batch_count=400\n",
    "iterations=10\n",
    "for iteration, duration, train_loss in bpr.train(iterations, batch_size, batch_count):\n",
    "    print iteration, duration, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Let's check the performance of our BPR model using overall AUC and coldstart AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5975979, 1772.3512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.evaluate(bpr.val_ratings, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.61772799, 1781.6512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.evaluate(bpr.test_ratings, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47666404, 2134.5886)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.evaluate(bpr.test_ratings, sample_size=1000, cold_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VBPR\n",
    "\n",
    "Now lets check VBPR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBPR - K=10, K2=10, reg_lf=10.00, reg_bias=0.01\n"
     ]
    }
   ],
   "source": [
    "#clear the graph if you rerun this cell\n",
    "tf.reset_default_graph()\n",
    "session = tf.Session()\n",
    "\n",
    "from models.vbpr import VBPR\n",
    "K=10\n",
    "K2=10\n",
    "reg=10.0\n",
    "bias_reg=0.01\n",
    "vbpr = VBPR(session, corpus, sampler, K, K2, reg, bias_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 26.6737940311 363.681\n",
      "2 25.7442569733 319.802\n",
      "3 26.2017970085 278.399\n",
      "4 25.1992931366 241.885\n",
      "5 26.0139992237 211.026\n",
      "6 25.1577601433 184.373\n",
      "7 24.7614409924 160.398\n",
      "8 25.1349849701 140.487\n",
      "9 25.5298659801 123.637\n"
     ]
    }
   ],
   "source": [
    "for iteration, duration, train_loss in vbpr.train(iterations, batch_size, batch_count):\n",
    "    print iteration, duration, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "Lets check overall validation auc, test auc and cold start auc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65634727, 998.43842)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbpr.evaluate(vbpr.val_ratings, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65708756, 989.82263)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbpr.evaluate(vbpr.test_ratings, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.55550295, 1212.0905)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbpr.evaluate(vbpr.test_ratings, sample_size=1000, cold_start=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VBPR Comments\n",
    "\n",
    "It's best to train the model up to `max_iterations` while keeping an eye on the iteration w/ the highest val-auc. Save this model and then evaluate on it. In the above demo we only trained on 10 iterations, however, in practice up to 50+ iterations is ususally requried to converge. Regardless, we can see that VBPR increased overall and cold start AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
